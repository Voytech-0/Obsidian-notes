# Revision IML
23:01:1809:06
Status:  #MachineLearning
Tags: 

---
- What is a feature?
- What is linear separability?
	- It is the quality of being able to be split by a hyperplane into two sets which are not intersecting with each other.
	- A single point is enough to make data not linear separable
- Why do we normalize and pre-process?
- Regularization vs normalization 
- Can regression labels be normalized?
	- Yes, as the labels could be vectors. Then, then would be normalized into a given range. We can also prevent models from predicting sth like negative age. 
- What can hurt the performance of ML model?
	- Noise, random features, features that do not predict the target value of interest, constant features, features with missing (or unclear) values, duplicate or correlated features
- What is the underlying concept of SVMs?
	- Maximum margin classifier 
- How do ML classification methods relate to Linear Separability?
	- Linearly separable data is the underlying concept of ML classification.
- The concept of the Kernel Trick 
- What makes a model linear?
	- It is a linear function
- why is k-NN (k-nearest neighbour) not linear?
	- Because it can work with non-linear data
- What is an **Ensemble**?
	- It creates more robust outcome in the end 
- One vs one and one vs all classifiers
- Understand cross-validation methods 
- Revise **regularization**

---
# References